{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation of 3D CNN Model \n",
    "\n",
    "This notebook demonstrates the process of evaluating a 3D Convolutional Neural Network (CNN) model on the a dataset. The workflow includes setting up the environment, loading the dataset, preparing the model, making predictions, and calculating various performance metrics. The notebook also visualizes the model's performance using a confusion matrix and ROC curve. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.abspath(os.path.join(os.path.dirname(os.path.abspath(\"__file__\")), '..')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General settings \n",
    "\n",
    "This section sets up the general settings and configurations required for the 3D CNN model. It includes importing necessary modules, setting random seeds for reproducibility, and defining important variables such as `JOB_ID`, `PHENOTYPE`, and `WEIGHTS_PATH`. These settings ensure that the environment is correctly configured for the subsequent steps in the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from settings import Settings\n",
    "\n",
    "settings = Settings()\n",
    "\n",
    "np.random.seed(settings.RANDOM_SEED)\n",
    "random.seed(settings.RANDOM_SEED)\n",
    "tf.random.set_seed(settings.RANDOM_SEED)\n",
    "\n",
    "JOB_ID = \"23187\"\n",
    "JOB_DIR_PATH = os.path.join(settings.BASE_DATA_DIR, \"jobs\", JOB_ID) \n",
    "\n",
    "ALL_DATASETS = {\n",
    "    # \"Advanced\": {\n",
    "    #     \"dataset_dir\": settings.ADVA_DATASET_DIR,\n",
    "    #     \"csv_path\": settings.ADVA_CSV_PATH,\n",
    "    #     'generator': None\n",
    "    # },\n",
    "    # \"ISPY1\": {\n",
    "    #     \"dataset_dir\": settings.ISPY1_DATASET_DIR,\n",
    "    #     \"csv_path\": settings.ISPY1_CSV_PATH,\n",
    "    # },\n",
    "    # \"ISPY2\": {\n",
    "    #     \"dataset_dir\": settings.ISPY2_DATASET_DIR,\n",
    "    #     \"csv_path\": settings.ISPY2_CSV_PATH,\n",
    "    # },\n",
    "    \"Setubal\": {\n",
    "        \"dataset_dir\": settings.SETUBAL_DATASET_DIR,\n",
    "        \"csv_path\": settings.SETUBAL_CSV_PATH,\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset loading \n",
    "\n",
    "This section loads the Duke dataset using the `DukeDataset` and `DukeDataGenerator` classes. The dataset is divided into training and testing sets, which are used to train and evaluate the 3D CNN model. The `train_generator` and `test_generator` objects are created to facilitate the loading and preprocessing of the data during training and testing phases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import BCCollectionDataset, DataGenerator\n",
    "\n",
    "for dataset_name in ALL_DATASETS.keys():\n",
    "    dataset = BCCollectionDataset(\n",
    "        ALL_DATASETS[dataset_name]['dataset_dir'],\n",
    "        ALL_DATASETS[dataset_name]['csv_path'],\n",
    "        crop_size=settings.INPUT_SIZE,\n",
    "    )\n",
    "    ALL_DATASETS[dataset_name]['generator'] = DataGenerator(\n",
    "        ALL_DATASETS[dataset_name]['dataset_dir'],\n",
    "        dataset=dataset,\n",
    "        dim=settings.INPUT_SIZE,\n",
    "        batch_size=settings.BATCH_SIZE,\n",
    "        positive_class=None,\n",
    "        autoencoder=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model preparation and evaluation \n",
    "\n",
    "This section prepares the 3D CNN model for evaluation by loading the model weights and making predictions on the test dataset. The `evaluate` function is defined to load the model, make predictions, and return the true and predicted labels. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error resizing volume P-SET1-000135-554003-1005: too many values to unpack (expected 3)\n",
      "Error resizing volume P-SET1-000135-554003-1005: too many values to unpack (expected 3)\n",
      "Error resizing volume P-SET1-000135-554003-1005: too many values to unpack (expected 3)\n",
      "Error resizing volume P-SET1-000135-554003-1005: too many values to unpack (expected 3)\n"
     ]
    }
   ],
   "source": [
    "def predict(generator, PHENOTYPE):\n",
    "    from tensorflow.keras.models import Model\n",
    "    \n",
    "    from models import CNN3D\n",
    "    \n",
    "    WEIGHTS_PATH = os.path.join(JOB_DIR_PATH, settings.PHENOTYPES[PHENOTYPE], \"checkpoints\", \"weights.h5\") \n",
    "    \n",
    "    generator.set_phenotype(PHENOTYPE)    \n",
    "    input_size = settings.INPUT_SIZE\n",
    "    model: Model = CNN3D(depth=input_size[0], width=input_size[1], height=input_size[2])\n",
    "    model.built = True\n",
    "    model.load_weights(WEIGHTS_PATH) \n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "\n",
    "    for i in range(len(generator)):\n",
    "        x, y = generator[i]\n",
    "        y_true.extend(y)\n",
    "        y_pred.extend(model.predict(x).ravel())\n",
    "\n",
    "    y_true = np.where(np.array(y_true) >= 1, 1, 0) \n",
    "    y_pred = np.array(y_pred)\n",
    "    \n",
    "    del model \n",
    "    return y_true, y_pred \n",
    "\n",
    "\n",
    "predictions = {}\n",
    "\n",
    "for dataset in ALL_DATASETS.keys():\n",
    "    if dataset not in predictions:\n",
    "        predictions[dataset] = {}\n",
    "    for PHENOTYPE in settings.PHENOTYPES:\n",
    "        y_true, y_pred = predict(ALL_DATASETS[dataset]['generator'], PHENOTYPE)\n",
    "        predictions[dataset][PHENOTYPE] = (y_true, y_pred) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating metrics \n",
    "\n",
    "This section evaluates the performance metrics of the 3D CNN model for a given phenotype. The `evaluate_all_metrics` function calculates and prints various metrics such as accuracy, precision, recall, AUC, and F1 score. It also generates a confusion matrix to visualize the model's performance. The results provide a comprehensive understanding of the model's effectiveness in classifying the phenotype."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phenotype: Luminal A (0)\n",
      "\n",
      "Accuracy: 0.3977\n",
      "Precision: 0.3500\n",
      "Recall: 0.9655\n",
      "AUC: 0.5617\n",
      "F1 Score: 0.5138\n",
      "\n",
      "Confusion Matrix:\n",
      "   0   1\n",
      "0  7  52\n",
      "1  1  28 \n",
      "\n",
      "\n",
      "Phenotype: Luminal B (1)\n",
      "\n",
      "Accuracy: 0.6477\n",
      "Precision: 0.5455\n",
      "Recall: 0.1875\n",
      "AUC: 0.6512\n",
      "F1 Score: 0.2791\n",
      "\n",
      "Confusion Matrix:\n",
      "    0  1\n",
      "0  51  5\n",
      "1  26  6 \n",
      "\n",
      "\n",
      "Phenotype: HER2 Enriched (2)\n",
      "\n",
      "Accuracy: 0.8068\n",
      "Precision: 0.0000\n",
      "Recall: 0.0000\n",
      "AUC: 0.2987\n",
      "F1 Score: 0.0000\n",
      "\n",
      "Confusion Matrix:\n",
      "    0  1\n",
      "0  71  6\n",
      "1  11  0 \n",
      "\n",
      "\n",
      "Phenotype: Triple Negative (3)\n",
      "\n",
      "Accuracy: 0.8523\n",
      "Precision: 0.7500\n",
      "Recall: 0.4737\n",
      "AUC: 0.5645\n",
      "F1 Score: 0.5806\n",
      "\n",
      "Confusion Matrix:\n",
      "    0  1\n",
      "0  66  3\n",
      "1  10  9 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_all_metrics(PHENOTYPE, y_true, y_pred):\n",
    "    from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    " \n",
    "    roc_auc = roc_auc_score(y_true, y_pred)\n",
    "    accuracy = accuracy_score(y_true, y_pred > 0.5)\n",
    "    precision = precision_score(y_true, y_pred > 0.5)\n",
    "    recall = recall_score(y_true, y_pred > 0.5)\n",
    "    f1 = f1_score(y_true, y_pred > 0.5)\n",
    "    conf_matrix = confusion_matrix(y_true, y_pred > 0.5)\n",
    "\n",
    "    metrics = {\n",
    "        \"Phenotype\": settings.PHENOTYPES[PHENOTYPE],\n",
    "        \"Accuracy\": accuracy,\n",
    "        \"Precision\": precision,\n",
    "        \"Recall\": recall,\n",
    "        \"AUC\": roc_auc,\n",
    "        \"F1 Score\": f1,\n",
    "        \"Confusion Matrix\": conf_matrix\n",
    "    }\n",
    "\n",
    "    return metrics \n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "metrics_results = {}\n",
    "\n",
    "for dataset in ALL_DATASETS.keys():\n",
    "    for PHENOTYPE in settings.PHENOTYPES:\n",
    "        y_true, y_pred = predictions[dataset][PHENOTYPE]\n",
    "        metrics = evaluate_all_metrics(PHENOTYPE, y_true, y_pred)\n",
    "        metrics_results[PHENOTYPE] = metrics\n",
    "        metrics = metrics_results[PHENOTYPE]\n",
    "        \n",
    "        print(f\"Phenotype: {metrics['Phenotype']} ({PHENOTYPE})\\n\")\n",
    "        print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "        print(f\"Precision: {metrics['Precision']:.4f}\")\n",
    "        print(f\"Recall: {metrics['Recall']:.4f}\")\n",
    "        print(f\"AUC: {metrics['AUC']:.4f}\")\n",
    "        print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
    "\n",
    "        conf_matrix_df = pd.DataFrame(\n",
    "            metrics[\"Confusion Matrix\"], index=np.unique(y_true), columns=np.unique(y_true)\n",
    "        )\n",
    "\n",
    "        print(\"\\nConfusion Matrix:\")\n",
    "        print(conf_matrix_df, \"\\n\\n\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ROC Curve\n",
    "\n",
    "The ROC curve is a graphical representation of the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings. It is used to evaluate the performance of a binary classifier. The area under the ROC curve (AUC) provides a single measure of the model's performance across all classification thresholds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "plt.figure()\n",
    "\n",
    "for i, PHENOTYPE in enumerate(settings.PHENOTYPES):\n",
    "    y_true, y_pred = predictions[PHENOTYPE]\n",
    "    metrics = metrics_results[PHENOTYPE]\n",
    "    fpr, tpr, _ = roc_curve(y_true, y_pred)\n",
    "    plt.plot(fpr, tpr, lw=2, label=f\"{settings.PHENOTYPES[PHENOTYPE]} (AUC = {metrics['AUC']:.4f})\")\n",
    "\n",
    "plt.plot([0, 1], [0, 1], color=\"black\", lw=2, linestyle=\"--\")\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlabel(\"False Positive Rate\")\n",
    "plt.ylabel(\"True Positive Rate\")\n",
    "plt.title(\"ROC Curves\")\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning curves\n",
    "\n",
    "This section plots the learning curves for the 3D CNN model, showing the training and validation AUC and loss over epochs. The learning curves provide insights into the model's performance and help identify potential issues such as overfitting or underfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_learning_curves(PHENOTYPE, show=True):\n",
    "    import os\n",
    "    import matplotlib.pyplot as plt\n",
    "    from tensorboard.backend.event_processing.event_accumulator import EventAccumulator\n",
    "\n",
    "    %matplotlib inline\n",
    "\n",
    "    # Define the path to the TensorBoard logs\n",
    "    log_dir_train = os.path.join(JOB_DIR_PATH, settings.PHENOTYPES[PHENOTYPE], \"logs\", \"train\")\n",
    "    log_dir_val = os.path.join(JOB_DIR_PATH, settings.PHENOTYPES[PHENOTYPE], \"logs\", \"validation\")\n",
    "\n",
    "    # Load the TensorBoard logs\n",
    "    event_acc_train = EventAccumulator(log_dir_train, size_guidance={'tensors': 0})\n",
    "    event_acc_train.Reload()\n",
    "    event_acc_val = EventAccumulator(log_dir_val, size_guidance={'tensors': 0})\n",
    "    event_acc_val.Reload()\n",
    "\n",
    "    # Extract the data for epoch_auc, epoch_val_auc, epoch_loss, and epoch_val_loss\n",
    "    epoch_auc_train = event_acc_train.Tensors('epoch_auc')\n",
    "    epoch_auc_val = event_acc_val.Tensors('epoch_auc')\n",
    "    epoch_loss_train = event_acc_train.Tensors('epoch_loss')\n",
    "    epoch_loss_val = event_acc_val.Tensors('epoch_loss')\n",
    "\n",
    "    # Extract the steps and values\n",
    "    steps_train = [x.step for x in epoch_auc_train]\n",
    "    auc_values_train = [tf.make_ndarray(x.tensor_proto).item() for x in epoch_auc_train]\n",
    "    auc_values_val = [tf.make_ndarray(x.tensor_proto).item() for x in epoch_auc_val]\n",
    "    loss_values_train = [tf.make_ndarray(x.tensor_proto).item() for x in epoch_loss_train]\n",
    "    loss_values_val = [tf.make_ndarray(x.tensor_proto).item() for x in epoch_loss_val]\n",
    "\n",
    "    # Plot the learning curves for AUC\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(steps_train, auc_values_train, label='Training AUC')\n",
    "    plt.plot(steps_train, auc_values_val, label='Validation AUC')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('AUC')\n",
    "    plt.title('AUC Learning Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "\n",
    "    # Plot the learning curves for Loss\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(steps_train, loss_values_train, label='Training Loss')\n",
    "    plt.plot(steps_train, loss_values_val, label='Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Learning Curves')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    \n",
    "    if show:\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "for PHENOTYPE in settings.PHENOTYPES:\n",
    "    plot_learning_curves(PHENOTYPE) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
